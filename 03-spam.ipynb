{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-spam.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oCKla53gJ7Jf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCKla53gJ7Jf",
        "colab_type": "text"
      },
      "source": [
        "# Filtado de mensajes spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RkG3LsqJq2N",
        "colab_type": "text"
      },
      "source": [
        "## Descripción del problema real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs8RCk7eJq2O",
        "colab_type": "text"
      },
      "source": [
        "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZnXmZMqJq2O",
        "colab_type": "text"
      },
      "source": [
        "## Descripción del problema en términos de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWDFXYanJq2O",
        "colab_type": "text"
      },
      "source": [
        "Se tiene una muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). La información está almacenada en el archivo `datos/spam-sms.zip`.El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBCk6SuIJq2P",
        "colab_type": "text"
      },
      "source": [
        "## Aproximaciones posibles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xND4oStmJq2P",
        "colab_type": "text"
      },
      "source": [
        "En este caso, se desea comparar los resultados de un modelo de redes neuronales artificiales y otras técnicas estadísticas para realizar la clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBFMtTBAJq2Q",
        "colab_type": "text"
      },
      "source": [
        "## Requerimientos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2OKyc6jJq2Q",
        "colab_type": "text"
      },
      "source": [
        "Usted debe:\n",
        "\n",
        "* Preprocesar los datos para representarlos usando bag-of-words.\n",
        "\n",
        "\n",
        "* Construir un modelo de regresión logística como punto base para la comparación con otros modelos más complejos.\n",
        "\n",
        "\n",
        "* Construir un modelo de redes neuronales artificiales. Asimismo, debe determinar el número de neuronas en la capa o capas ocultas.\n",
        "\n",
        "\n",
        "* Utiizar una técnica como crossvalidation u otra similar para establecer la robustez del modelo.\n",
        "\n",
        "\n",
        "* Presentar métricas de desempeño para establecer las bondades y falencias de cada clasificador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxaGT_0BKJK8",
        "colab_type": "text"
      },
      "source": [
        "# Solución"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKWKks6oJq2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1ca2ea76-d4d8-42df-e278-d1b4c7ba05a8"
      },
      "source": [
        "# Imports\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext rpy2.ipython\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import sklearn.neural_network\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
            "  from pandas.core.index import Index as PandasIndex\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n",
            "  warnings.warn('pandas >= 1.0 is not supported.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX6lgYxBWdHk",
        "colab_type": "text"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyuUNzxPWfTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7d51865f-1253-4f4b-dd2b-b7799977e3c4"
      },
      "source": [
        "dataFrame = pd.read_csv(\n",
        "  \"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/sms-spam.csv\",\n",
        "  sep = ',',\n",
        "  thousands = None,\n",
        "  decimal = '.',\n",
        "  encoding='latin-1'\n",
        ")\n",
        "\n",
        "dataFrame.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQpitP1PW3zU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "311f2a24-b151-4c0b-9d6d-352d5107f1e1"
      },
      "source": [
        "dataFrame.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5574</td>\n",
              "      <td>5574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4827</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type                    text\n",
              "count   5574                    5574\n",
              "unique     2                    5160\n",
              "top      ham  Sorry, I'll call later\n",
              "freq    4827                      30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koRhWEUqW_xF",
        "colab_type": "text"
      },
      "source": [
        "## Distribución de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzsR-ItxYjK8",
        "colab_type": "text"
      },
      "source": [
        "Gráfica que compara número de mensajes *ham* y *spam* que contiene el data set cargado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axGHwEzkXLPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "3cc709c8-99d8-4826-f0f8-c783b0bfe118"
      },
      "source": [
        "dataFrame.type.value_counts().plot.bar();"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAELCAYAAAA1AlaNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD5DMF9W0DjGpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoDZeZTgXh2N",
        "colab_type": "text"
      },
      "source": [
        "## Aplicación de Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xziuyc1rXhXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "a8610087-dc2c-436d-994b-ac2c8a74d62f"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "dataFrame['stemmed'] = dataFrame.text.apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split() ]))\n",
        "dataFrame.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>Go until jurong point, crazy.. avail onli in b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar... joke wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entri in 2 a wkli comp to win FA cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say so earli hor... U c alreadi then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah I don't think he goe to usf, he live aroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>freemsg hey there darl it' been 3 week' now an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>As per your request 'mell mell (oru minnaminun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>winner!! As a valu network custom you have bee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>had your mobil 11 month or more? U R entitl to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                            stemmed\n",
              "0   ham  ...  Go until jurong point, crazy.. avail onli in b...\n",
              "1   ham  ...                        Ok lar... joke wif u oni...\n",
              "2  spam  ...  free entri in 2 a wkli comp to win FA cup fina...\n",
              "3   ham  ...  U dun say so earli hor... U c alreadi then say...\n",
              "4   ham  ...  nah I don't think he goe to usf, he live aroun...\n",
              "5  spam  ...  freemsg hey there darl it' been 3 week' now an...\n",
              "6   ham  ...  even my brother is not like to speak with me. ...\n",
              "7   ham  ...  As per your request 'mell mell (oru minnaminun...\n",
              "8  spam  ...  winner!! As a valu network custom you have bee...\n",
              "9  spam  ...  had your mobil 11 month or more? U R entitl to...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_diJrWAbZxO2",
        "colab_type": "text"
      },
      "source": [
        "## Acondicionamiento de los datos\n",
        "\n",
        "Utilizamos *CountVectorizer* para representar los datos como *Bag-of-words*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mDyhGkxZ0G0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "160fb77c-9b08-431c-9b21-58ce784257df"
      },
      "source": [
        "count_vect = CountVectorizer(\n",
        "    analyzer='word',        # a nivel de palabra\n",
        "    lowercase=True,         # convierte a minúsculas\n",
        "    stop_words='english',   # stop_words en inglés\n",
        "    binary=True,            # Los valores distintos de cero son fijados en 1\n",
        "    min_df=5                # ignora palabras con baja freq\n",
        ")\n",
        "\n",
        "\n",
        "##\n",
        "## Aplica la función al texto\n",
        "##\n",
        "dtm = count_vect.fit_transform(dataFrame.stemmed).toarray()\n",
        "\n",
        "##\n",
        "## Las filas contienen los mensajes\n",
        "## y las clomunas los términos\n",
        "##\n",
        "\n",
        "dtm.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5574, 1540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDwnigKdIBl",
        "colab_type": "text"
      },
      "source": [
        "## Modelo de regresión logística\n",
        "Construcción del modelo de regresión logística validando su robustez con *CrossValidation* de 5 iteraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFKjaj93ee6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c68c4b04-10e6-43cc-d416-bfdcf5211323"
      },
      "source": [
        "regresionLogistica = linear_model.LogisticRegression()\n",
        "\n",
        "# Datos base\n",
        "dEntrada = dtm[0:][:].copy()\n",
        "dSalida = dataFrame[[\"type\"]][:].copy()\n",
        "\n",
        "# Nuestro set de datos de prueba siempre será de 100 elementos\n",
        "tSetPrueba = 100\n",
        "\n",
        "# Evaluaremos 5 corridas para el CrossValidation\n",
        "corridas = 5\n",
        "\n",
        "# Matriz de confusión acumulada\n",
        "porcentaje = 0\n",
        "\n",
        "for corrida in range(0, corridas):\n",
        "  datosEntrenamientoEntrada = []\n",
        "  datosEntrenamientoSalida = []\n",
        "  datosPruebaEntrada = []\n",
        "  datosPruebaSalida = []\n",
        "\n",
        "  # Obtenemos el indice inicial para el set de pruebas aleatoriamente\n",
        "  # Garantiza que todos los sets tengan 100 elementos\n",
        "  i = random.randrange(0, len(dEntrada) - tSetPrueba)\n",
        "\n",
        "  datosEntrenamientoEntrada.extend(dEntrada[:i])\n",
        "  datosEntrenamientoEntrada.extend(dEntrada[(i + tSetPrueba):])\n",
        "\n",
        "  datosEntrenamientoSalida = np.append(dSalida[:i], dSalida[(i + tSetPrueba):])\n",
        "\n",
        "  datosPruebaEntrada.extend(dEntrada[i:i+tSetPrueba])\n",
        "  datosPruebaSalida = dSalida[i:i+tSetPrueba]\n",
        "\n",
        "  regresionLogistica.fit(datosEntrenamientoEntrada, datosEntrenamientoSalida)\n",
        "  pronosticos = regresionLogistica.predict(np.array(datosPruebaEntrada))\n",
        "\n",
        "  mConf = confusion_matrix(y_true = datosPruebaSalida.copy(), y_pred = pronosticos)\n",
        "  porcentaje += (mConf[0][0] + mConf [1][1]) / mConf.sum()\n",
        "\n",
        "print(porcentaje/corridas)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9720000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnNPCQjeBcvg",
        "colab_type": "text"
      },
      "source": [
        "Para el *CrossValidation* se están ejecutando 5 corridas las cuales calculan 5 sets aleatorios para entrenamiento y pruebas, con la caracteristica de que cada set de pruebas calculado tiene un tamaño de 100 elementos.\n",
        "\n",
        "Como resultado del modelo de regresión logística, se obtiene que la exactitud promedio de las 5 corridas del *CrossValidation* es de 97.2% aproximadamnete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INYGxK_Mbf8y",
        "colab_type": "text"
      },
      "source": [
        "## Red Neuronal\n",
        "Costruccion de red neuronal:\n",
        "*   Tasa de aprendizaje de 0.01\n",
        "*   Máximas neuronas a evaluar 10\n",
        "*   Función de activacion logistica\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMx8ffnCb1Ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "270ef4ec-1e6d-47d7-c217-74e40b1a9a85"
      },
      "source": [
        "# Configuración red neuronal\n",
        "maxNeuronas = 10\n",
        "tasaApren = 0.01\n",
        "\n",
        "# Datos base\n",
        "dEntrada = dtm[0:][:].copy()\n",
        "dSalida = dataFrame[[\"type\"]][:].copy()\n",
        "\n",
        "# Nuestro set de datos de prueba siempre será de 100 elementos\n",
        "tSetPrueba = 100\n",
        "\n",
        "# Evaluaremos 5 corridas\n",
        "corridas = 5\n",
        "\n",
        "# Matriz de confusión acumulada\n",
        "mejorPorcentaje = 0\n",
        "umbral = 0.05\n",
        "canNeuMejorResultado = 0\n",
        "\n",
        "for neuCapaOculta in range (1, maxNeuronas + 1):\n",
        "  mlp = sklearn.neural_network.MLPClassifier(\n",
        "                  hidden_layer_sizes = (neuCapaOculta,),  # Una capa oculta con una neurona\n",
        "                  activation = 'logistic',                # {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
        "                  learning_rate_init = tasaApren,         # Valor de la tasa de aprendizaje\n",
        "                  learning_rate = 'adaptive',             # La tasa no se adapta automáticamente          \n",
        "                  shuffle = True,             \n",
        "                  warm_start = True) \n",
        "  \n",
        "  porcenRedNeuronal = 0\n",
        "  mConfPorcentaje = 0\n",
        "  for corrida in range (0, corridas):\n",
        "    datosEntrenamientoEntrada = []\n",
        "    datosEntrenamientoSalida = []\n",
        "    datosPruebaEntrada = []\n",
        "    datosPruebaSalida = []\n",
        "\n",
        "    # Obtenemos el indice inicial para el set de pruebas aleatoriamente\n",
        "    # Garantiza que todos los sets tengan 100 elementos\n",
        "    i = random.randrange(0, len(dEntrada) - tSetPrueba)\n",
        "\n",
        "    datosEntrenamientoEntrada.extend(dEntrada[:i])\n",
        "    datosEntrenamientoEntrada.extend(dEntrada[(i + tSetPrueba):])\n",
        "\n",
        "    datosEntrenamientoSalida = np.append(dSalida[:i], dSalida[(i + tSetPrueba):])\n",
        "\n",
        "    datosPruebaEntrada.extend(dEntrada[i:i+tSetPrueba])\n",
        "    datosPruebaSalida = dSalida[i:i+tSetPrueba]\n",
        "\n",
        "    mlp.fit(datosEntrenamientoEntrada, datosEntrenamientoSalida)\n",
        "    pronosticos = mlp.predict(np.array(datosPruebaEntrada))\n",
        "\n",
        "    mConf = confusion_matrix(y_true = datosPruebaSalida.copy(), y_pred = pronosticos)\n",
        "    mConfPorcentaje += (mConf[0][0] + mConf [1][1]) / mConf.sum()\n",
        "  porcenRedNeuronal = mConfPorcentaje / corridas\n",
        "\n",
        "  if (porcenRedNeuronal - mejorPorcentaje > umbral) :\n",
        "    mejorPorcentaje = porcenRedNeuronal\n",
        "    canNeuMejorResultado = neuCapaOculta\n",
        "\n",
        "print(\"Porcentaje: \" ,mejorPorcentaje)\n",
        "print(\"Neuronas: \" ,canNeuMejorResultado)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Porcentaje:  0.998\n",
            "Neuronas:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR4rqZdBX9d6",
        "colab_type": "text"
      },
      "source": [
        "Para el *CrossValidation* se están ejecutando 5 corridas las cuales calculan 5 sets aleatorios para entrenamiento y pruebas, con la caracteristica de que cada set de pruebas calculado tiene un tamaño de 100 elementos. Dicho cálculo se ejecuta por cada red neuronal y con base en el promedio de los resultados se compara con las demas redes neuronales para identificar la cantidad de neuronas óptimas en el modelo.\n",
        "\n",
        "Luego de evaluar el modelo, obtenemos como mejor resultado una red neuronal con 1 neurona en la capa oculta y una exactitud de 99.8% aproximadamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfXJSH3QmSOw",
        "colab_type": "text"
      },
      "source": [
        "# Conclusión\n",
        "\n",
        "Comparando ambos modelos y aplicando técnicas como *CrossValidation* para evaluar la robuztes de los modelos, podemos sugerir que el modelo más exacto en promedio es la red neuronal con una neurona en la capa oculta la cual presenta mas de una unidad de mejora en la exactitud de los resultados.\n",
        "\n",
        "*   Regresión logística : 97.2%\n",
        "*   Red neuronal : 99.8%\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBBPEkrenCxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}